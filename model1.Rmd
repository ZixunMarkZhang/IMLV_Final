# [Logistic Regression]
```{r}
#data cleaning
bankfull <- read.csv("bank-additional-full.csv", sep=";")
#delete month and dat of week as they are irrelevant. Eliminate duration as it has extremely high correlation with target
bankfull = subset(bankfull, select = -c(month,day_of_week,duration) )
#delete all rows with unknown values
bankfull<-subset(bankfull, (job!='unknown') & (marital!='unknown') & 
               (education!='unknown')& (default!='unknown') & 
               (housing!='unknown') & (loan!='unknown'))
#keep binary variables
bank = subset(bankfull,select = c(marital, default, housing, loan,contact))
#process numerical values
bank$age = scale(bankfull$age)
bank$campaign = scale(bankfull$campaign)
bank$pdays =scale(bankfull$pdays)
bank$previous =scale(bankfull$previous)
bank$emp.var.rate =scale(bankfull$emp.var.rate)
bank$cons.price.idx =scale(bankfull$cons.price.idx)
bank$cons.conf.idx =scale(bankfull$cons.conf.idx)
bank$euribor3m =scale(bankfull$euribor3m)
bank$nr.employed =scale(bankfull$nr.employed)
bank$y = (bankfull$y=='yes')
library(caret)

dummy <- dummyVars(" ~ .", subset(bankfull, select = c(education,job,poutcome)))
df <- data.frame(predict(dummy, newdata = subset(bankfull, select = c(education,job,poutcome)))) 
bank = cbind(df,bank)
set.seed(5293)
n <- nrow(df)
train <- sample(n, .8*n)
train_dat <-bank[train, ]
test_dat<- bank[-train,]
```

```{r}
#build Logistic regression model
fullmod<-glm(y~.,data=train_dat,family=binomial(link = 'logit'))
LRpred = predict(fullmod,test_dat,type = 'response')
```

```{r}
library(caret)
library(reshape2)
library(tibble)
library(ggplot2)
library(tidyverse)
importance = melt(t(na.omit(fullmod$coefficients[-1])))
colnames(importance) = c('var1','var','coefficient')
ggplot(data=importance, aes(y=reorder(var,abs(coefficient)), x=coefficient)) +
  geom_bar(stat="identity")

```
    After the logistic regression models are built, we may access the feature importance by visualize the coefficient. The plot above shows the magnitude of significance for each variable with a descending order of their absolute value. It is obvious that the default value has the largest influence on the predicted probability. However, that's mostly because of the default yes record in the data set according to the EDA part. Despite the default values, whether the person is illiterate, employment variable rate, whether the contacting is via telephone, and the outcome of previous campaign has remarkable impact on the prediction. However, the coefficient of default is too large that we actually can not assess the exact coefficient of variables by visualization; hence we may eliminate the default from the graph and get a new bar plot as follows.

```{r}
importance1 = subset(importance,var!='defaultyes')
ggplot(data=importance1, aes(y=reorder(var,abs(coefficient)), x=coefficient)) +
  geom_bar(stat="identity")+
  geom_text(aes(label = round(coefficient,2)))
```
From this plot, we may find that there are some variables that creates minor impact in our full regression model. Specifically speaking, in this plot, 
housingyes,, jobhousemaid, previous, jobself.employed, jobmanagement,loanyes, jobtechnician, and age have coefficient under 0.05. We will examine a reduced model without these listed variable in the following analysis.
```{r}
get_rates <- function(threshold, actual, response) {
  predicted <- ifelse(response < threshold, 0, 1)
  
  TP <- sum(actual == 1 & predicted == 1)
  FP <- sum(actual == 0 & predicted == 1)
  TN <- sum(actual == 0 & predicted == 0)
  FN <- sum(actual == 1 & predicted == 0)
  
  tpr <- TP/(TP + FN)
  fpr <- FP/(TN + FP)  
  
  data.frame(threshold, tpr, fpr)
  
}


rocdf <- map_df(seq(0, 1, .01), get_rates, test_dat$y==1, LRpred)
rocdf <- rocdf |> 
  mutate(label = ifelse(threshold %in% seq(0, 1, .01),
                        threshold, NA))
library(ggrepel)
g <- ggplot(rocdf, aes(x = fpr, y = tpr, label = label)) +
  geom_point() +
  geom_path() +
  geom_label_repel(color = "blue", size = 2)
plotly::ggplotly(g)
```
